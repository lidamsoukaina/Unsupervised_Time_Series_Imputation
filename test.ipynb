{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bb48b7-d2b8-4964-8c6a-38f2dc0a8039",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e0cff-40f0-49ef-99d4-534e85e867ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_preparation.generate_sets import agglomerate_data, create_train_val_test_sets\n",
    "from data_preparation.datasets import main as generate_loaders_and_test_nan\n",
    "from data_preparation.induce_nans import main as generate_test_masked\n",
    "from data_preparation.preprocessing import preprocess_data\n",
    "\n",
    "from models.MLP_AE import FullyConnectedAutoencoder\n",
    "from models.Conv_AE import ConvAutoencoder\n",
    "from models.LSTM_AE import LSTM_Autoencoder\n",
    "from models.Transformer_Encoder import make_model\n",
    "\n",
    "from training.train import train_model\n",
    "\n",
    "from evaluations.nn_loss import ORT_MIT_Loss\n",
    "from evaluations.utils import load_model, count_parameters\n",
    "from evaluations.predict import predict\n",
    "from evaluations.eval_classical_methods import evaluate_set\n",
    "from evaluations.mse import evaluate_imputation_mse\n",
    "from evaluations.t_test import t_test\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import configue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('figure', figsize=(12, 3))\n",
    "\n",
    "# configue\n",
    "config = configue.load(\"./config.yaml\")\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(config[\"random_state\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0d537b6-fef0-4d57-a215-85595eef20a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Input Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dd4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaling and removing unused columns\n",
    "## !! If you data contains non numerical features please drop them or encode them !!\n",
    "train, val, test = preprocess_data(config[\"path_train\"], config[\"path_val\"], config[\"path_test\"], MinMaxScaler(), config[\"columns_to_drop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56749288-6081-4daf-829a-03de84a1c8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Induce NaNs in test set\n",
    "test_nan, test_mask = generate_test_masked(config,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db3d28-a72a-4051-a730-79890830b382",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **DL models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec91f2-2a12-4ee4-9708-9db1a725cf31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Train the AutoEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277779f-9340-4a78-9559-73f773685a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_ae = configue.load(\"./training/config_AE.yaml\")\n",
    "train_loader_ae, val_loader_ae, test_loader_ae = generate_loaders_and_test_nan(config, config_ae,train, val, test, test_nan, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac5a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = ORT_MIT_Loss(config_ae[\"loss_parameter\"])\n",
    "input_dim = train.shape[1] * config_ae[\"sequence_length\"]\n",
    "## output dimension\n",
    "output_dim = input_dim\n",
    "# Hyperparameters\n",
    "reduction_parameter = config_ae[\"reduction_parameter\"]\n",
    "hidden_dim1 = int(input_dim * reduction_parameter)\n",
    "hidden_dim2 = int(hidden_dim1 * reduction_parameter)\n",
    "# Init model and loss function\n",
    "model_ae = FullyConnectedAutoencoder(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "if torch.cuda.is_available():\n",
    "    model_ae = model_ae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b75ed-6dc8-4a31-95e6-e40b9dc6ebf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list,model_ae_PATH = train_model(model_ae,loss_fn,config_ae,input_dim,train_loader_ae,val_loader_ae, is_flatten=True, is_TS=False, is_warmed= True)\n",
    "df = pd.DataFrame({'epochs':[i for i in range(config_ae[\"epochs\"])],'train_loss': train_loss_list,'val_loss': val_loss_list})\n",
    "df.plot(x=\"epochs\", y=[\"train_loss\", \"val_loss\"],kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad690c-0888-4f64-8537-b6707dc36779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model_ae_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea24b168",
   "metadata": {},
   "source": [
    "## **Train the ConvAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e171b-b763-4f71-8966-89efe703df5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_conv_ae = configue.load(\"./training/config_convAE.yaml\")\n",
    "train_loader_conv_ae, val_loader_conv_ae, test_loader_conv_ae = generate_loaders_and_test_nan(config, config_conv_ae,train, val, test, test_nan, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b9eb9-991e-4e8b-9541-9e554ae9425f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = ORT_MIT_Loss(config_conv_ae[\"loss_parameter\"])\n",
    "# Parameters\n",
    "d_input = train.shape[1]\n",
    "input_dim = train.shape[1] * config_conv_ae[\"sequence_length\"]\n",
    "# Hyperparameters\n",
    "reduction_parameter = config_conv_ae[\"reduction_parameter\"]\n",
    "hidden_dim1 = int(input_dim * reduction_parameter)\n",
    "hidden_dim2 = int(hidden_dim1 * reduction_parameter)\n",
    "hidden_dim3 = int(hidden_dim2 * reduction_parameter)\n",
    "#init model\n",
    "model_conv_ae = ConvAutoencoder(config_conv_ae[\"sequence_length\"],d_input,hidden_dim1, hidden_dim2,hidden_dim3)\n",
    "if torch.cuda.is_available():\n",
    "    model_conv_ae = model_conv_ae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a6481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list,model_conv_ae_path = train_model(model_conv_ae,loss_fn,config_conv_ae,input_dim,train_loader_conv_ae,val_loader_conv_ae, is_flatten=False, is_TS=False, is_warmed= False)\n",
    "df = pd.DataFrame({'epochs':[i for i in range(config_conv_ae[\"epochs\"])],'train_loss': train_loss_list,'val_loss': val_loss_list})\n",
    "df.plot(x=\"epochs\", y=[\"train_loss\", \"val_loss\"],kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497e4e9-3427-467b-a2ae-19873999ca1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model_conv_ae_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26d74c-37f0-41d7-b643-3d4b8653cb65",
   "metadata": {},
   "source": [
    "## **Train LSTM AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854442dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_lstm_ae = configue.load(\"./training/config_LSTM_AE.yaml\")\n",
    "train_loader_lstm_ae, val_loader_lstm_ae, test_loader_lstm_ae = generate_loaders_and_test_nan(config, config_lstm_ae,train, val, test, test_nan, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9a608-2790-4fdf-9523-ed83c558abd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = ORT_MIT_Loss(config_lstm_ae[\"loss_parameter\"])\n",
    "# Parameters\n",
    "d_input = train.shape[1]\n",
    "#Hyperparameters\n",
    "reduction_parameter = config_lstm_ae[\"reduction_parameter\"]\n",
    "embedding_size = int(d_input * reduction_parameter)\n",
    "#init model and loss\n",
    "model_ae_lstm = LSTM_Autoencoder(config_lstm_ae[\"sequence_length\"],d_input,embedding_size)\n",
    "if torch.cuda.is_available():\n",
    "    model_ae_lstm = model_ae_lstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12ffff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list,model_ae_lstm_path = train_model(model_ae_lstm,loss_fn,config_lstm_ae,d_input,train_loader_lstm_ae,val_loader_lstm_ae, is_flatten=False, is_TS=False, is_warmed= True)\n",
    "df = pd.DataFrame({'epochs':[i for i in range(config_lstm_ae[\"epochs\"])],'train_loss': train_loss_list,'val_loss': val_loss_list})\n",
    "df.plot(x=\"epochs\", y=[\"train_loss\", \"val_loss\"],kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aef257-2b63-4160-9b14-2b3c2a14e636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model_ae_lstm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7020b0c-01b6-45da-8c2b-8c6df6ae057c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Train transformer Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c670e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_ts = configue.load(\"./training/config_TS.yaml\")\n",
    "train_loader_ts, val_loader_ts, test_loader_ts = generate_loaders_and_test_nan(config, config_ts,train, val, test, test_nan, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29d8ca-ecb5-47c4-86c1-db20cc2850d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = ORT_MIT_Loss(config_ts[\"loss_parameter\"])\n",
    "# Parameters\n",
    "d_input = train.shape[1]\n",
    "TS_model = make_model(d_input=d_input, N=config_ts[\"N\"], d_model=config_ts[\"d_model\"], d_ff=config_ts[\"d_ff\"], h=config_ts[\"h\"], dropout=config_ts[\"dropout\"])\n",
    "if torch.cuda.is_available():\n",
    "    TS_model = TS_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784dc53b-ffdd-40ab-a21a-cf516888f287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list,TS_model_Path = train_model(TS_model,loss_fn,config_ts,d_input,train_loader_ts,val_loader_ts, is_flatten=False, is_TS=True, is_warmed= False)\n",
    "df = pd.DataFrame({'epochs':[i for i in range(config_ts[\"epochs\"])],'train_loss': train_loss_list,'val_loss': val_loss_list})\n",
    "df.plot(x=\"epochs\", y=[\"train_loss\", \"val_loss\"],kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4e4f3-e507-4060-a8b7-738f5ef4c678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# value in the order of 10-19, 10-20\n",
    "print(TS_model_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a52ee2-a17e-4cdc-9fbc-eeae828a8e34",
   "metadata": {},
   "source": [
    "# **Synthesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7dc4d-7b7d-4caf-9d2a-d2f586758dd0",
   "metadata": {},
   "source": [
    "## **Final Models Complexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6af48-8b29-43ff-b7fc-f3afaee18b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final models complexity\n",
    "count_params = [count_parameters(model) for model in [TS_model,model_ae_lstm,model_ae,model_conv_ae]]\n",
    "column_model_complexity = pd.DataFrame(count_params, columns=[\"model_complexity\"], index=[\"Transformer_encoder\",\"LSTM_autoencoder\",\"Autoencoder\",\"Conv_autoencoder\"]) \n",
    "column_model_complexity.sort_values(by=[\"model_complexity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9191764-d140-4d99-a5c7-856be2a25b27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f3cd7-4ff6-42be-896e-3919c15a3d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AE model evaluation\n",
    "model_ae=load_model(model_ae,model_ae_PATH) #get AE model\n",
    "test_predicted, test_or = predict(model_ae, test,config_ae[\"sequence_length\"],test_loader_ae, is_flatten = True, is_TS = False )\n",
    "mse_ae_median = evaluate_imputation_mse(test_or, test_predicted, test_mask,\"AE_median\")\n",
    "t_test_ae_median = t_test(test_or, test_predicted, test_mask, \"AE_median\")\n",
    "test_predicted, test_or = predict(model_ae, test,config_ae[\"sequence_length\"],test_loader_ae, is_flatten = True, is_TS = False, strategy =\"mean\" )\n",
    "mse_ae_mean = evaluate_imputation_mse(test_or, test_predicted, test_mask,\"AE_mean\")\n",
    "t_test_ae_mean = t_test(test_or, test_predicted, test_mask, \"AE_mean\")\n",
    "print(\"done with ae\")\n",
    "\n",
    "#AE_conv model eval\n",
    "model_conv_ae=load_model(model_conv_ae,model_conv_ae_path) #get Conv_AE model\n",
    "test_predicted, test_or = predict(model_conv_ae, test,config_conv_ae[\"sequence_length\"],test_loader_conv_ae, is_flatten = False, is_TS = False )\n",
    "mse_conv_ae_median = evaluate_imputation_mse(test, test_predicted, test_mask,\"Conv_autoencoder_median\")\n",
    "t_test_conv_ae_median = t_test(test_or, test_predicted, test_mask, \"Conv_autoencoder_median\")\n",
    "test_predicted, test_or = predict(model_conv_ae, test,config_conv_ae[\"sequence_length\"],test_loader_conv_ae, is_flatten = False, is_TS = False, strategy =\"mean\" )\n",
    "mse_conv_ae_mean = evaluate_imputation_mse(test, test_predicted, test_mask,\"Conv_autoencoder_mean\")\n",
    "t_test_conv_ae_mean = t_test(test_or, test_predicted, test_mask, \"Conv_autoencoder_mean\")\n",
    "print(\"done with convae\")\n",
    "\n",
    "# AE_LSTM model eval\n",
    "model_ae_lstm=load_model(model_ae_lstm,model_ae_lstm_path) #get LSTM_AE model\n",
    "test_predicted, test_or = predict(model_ae_lstm, test,config_lstm_ae[\"sequence_length\"],test_loader_lstm_ae, is_flatten = False, is_TS = False )\n",
    "mse_lstm_ae_median = evaluate_imputation_mse(test, test_predicted, test_mask,\"LSTM_autoencoder_median\")\n",
    "t_test_lstm_ae_median = t_test(test_or, test_predicted, test_mask, \"LSTM_autoencoder_median\")\n",
    "test_predicted, test_or = predict(model_ae_lstm, test,config_lstm_ae[\"sequence_length\"],test_loader_lstm_ae, is_flatten = False, is_TS = False, strategy =\"mean\" )\n",
    "mse_lstm_ae_mean = evaluate_imputation_mse(test, test_predicted, test_mask,\"LSTM_autoencoder_mean\")\n",
    "t_test_lstm_ae_mean = t_test(test_or, test_predicted, test_mask, \"LSTM_autoencoder_mean\")\n",
    "print(\"done with LSTM ae\")\n",
    "\n",
    "# Transformer\n",
    "info = torch.load(TS_model_Path)[\"config_model\"]\n",
    "model_TS = make_model(d_input=d_input, N=info['N'], d_model=info['d_model'], d_ff=info['d_ff'], h=info['h'], dropout=info['dropout'])\n",
    "model_TS=load_model(model_TS,TS_model_Path) #get LSTM_AE model\n",
    "if torch.cuda.is_available():\n",
    "    model_TS = model_TS.cuda()\n",
    "\n",
    "test_predicted, test_or = predict(model_TS, test,config_ts[\"sequence_length\"],test_loader_ts, is_flatten = False, is_TS = True )\n",
    "mse_ts_median = evaluate_imputation_mse(test, test_predicted, test_mask,\"Transformer_encoder_median\")\n",
    "t_test_ts_median  = t_test(test_or, test_predicted, test_mask, \"Transformer_encoder_median\")\n",
    "test_predicted, test_or = predict(model_TS, test,config_ts[\"sequence_length\"],test_loader_ts, is_flatten = False, is_TS = True, strategy='mean')\n",
    "mse_ts_mean = evaluate_imputation_mse(test, test_predicted, test_mask,\"Transformer_encoder_mean\")\n",
    "t_test_ts_mean  = t_test(test_or, test_predicted, test_mask, \"Transformer_encoder_mean\")\n",
    "print(\"done with ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36344e-d4c3-434c-b8a9-5ae99d4c9b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluations, tests_classique = evaluate_set(config[\"class_methods\"],test,test_nan,test_mask, config[\"random_state\"])\n",
    "evaluations=pd.concat([evaluations,mse_lstm_ae_median,mse_ae_median,mse_conv_ae_median,mse_ts_median, mse_lstm_ae_mean,mse_ae_mean,mse_conv_ae_mean, mse_ts_mean],axis=0) #[evaluations,mse_ts,mse_lstm_ae,mse_ae,mse_conv_ae]\n",
    "evaluations = evaluations.sort_values(by=[\"mse\"])\n",
    "evaluations.reset_index(drop=True, inplace=True)\n",
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe385e9-80f4-48c0-bc12-307e5bb582c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='mse',y='method',data=evaluations)\n",
    "plt.title('MSE evaluation of all approaches in test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c7f7f-d77f-41b1-8da9-417cf2d6a52a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Distribution t-test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af2604-feb0-42a6-9417-e94fd4d3d22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests_classique=pd.concat([tests_classique,t_test_ae_mean,t_test_lstm_ae_mean,t_test_conv_ae_mean,t_test_ts_mean,t_test_ae_median,t_test_lstm_ae_median,t_test_conv_ae_median,t_test_ts_median],axis=0) \n",
    "tests_classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44193302-6124-4f81-b7de-0e74f608df5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tests_classique[\"same_distribution\"] = tests_classique[\"same_distribution\"].astype(int)\n",
    "tests_classique.drop(['column','p-value'],axis = 1,inplace=True)\n",
    "tests_classique = tests_classique.groupby(['method'],as_index=False).sum()\n",
    "tests_classique = tests_classique.sort_values(by=[\"same_distribution\"],ascending=False)\n",
    "tests_classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678683c-591a-42ad-a2c1-58695b173a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='same_distribution',y='method',data=tests_classique)\n",
    "plt.title(\"total number of features with same distribution after imputation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
