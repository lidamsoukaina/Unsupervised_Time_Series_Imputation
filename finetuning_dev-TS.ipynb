{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bb48b7-d2b8-4964-8c6a-38f2dc0a8039",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468e0cff-40f0-49ef-99d4-534e85e867ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-42kmy51x because the default path (/home/upbeat_liskov/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from data_preparation.generate_sets import main as generate_sets\n",
    "from data_preparation.datasets import main as generate_loaders_and_test_nan\n",
    "from data_preparation.induce_nans import main as generate_test_masked\n",
    "from data_preparation.preprocessing import preprocess_data\n",
    "\n",
    "from models.MLP_AE import FullyConnectedAutoencoder\n",
    "from models.Conv_AE import ConvAutoencoder\n",
    "from models.LSTM_AE import LSTM_Autoencoder\n",
    "from models.Transformer_Encoder import make_model\n",
    "\n",
    "from training.train import train_model\n",
    "\n",
    "from evaluations.nn_loss import ORT_MIT_Loss\n",
    "from evaluations.utils import load_model, count_parameters\n",
    "from evaluations.predict import predict\n",
    "from evaluations.eval_classical_methods import evaluate_set\n",
    "from evaluations.mse import evaluate_imputation_mse\n",
    "from evaluations.t_test import t_test\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from optuna.visualization.matplotlib import plot_optimization_history, plot_param_importances, plot_parallel_coordinate\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import configue\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('figure', figsize=(12, 3))\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba382d84-7af4-49d5-b8a1-6eff0d705c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4285116e50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configue\n",
    "config = configue.load(\"./config.yaml\")\n",
    "torch.manual_seed(config[\"random_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d537b6-fef0-4d57-a215-85595eef20a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56b3eb4-2339-48f2-839d-a58a989fc717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation and test sets created\n"
     ]
    }
   ],
   "source": [
    "generate_sets(config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02431299-5cca-4e42-982d-759c7be8221f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking done\n"
     ]
    }
   ],
   "source": [
    "train, val, test = preprocess_data(config[\"path_train\"], config[\"path_val\"], config[\"path_test\"], MinMaxScaler(), config[\"columns_to_drop\"])\n",
    "test_nan, test_mask = generate_test_masked(config,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db3d28-a72a-4051-a730-79890830b382",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **DL models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388e45c4-7e9a-46b9-b0ef-c3fd3558abe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters Intervals\n",
    "## Learning rate\n",
    "LR = [0.0001, 0.001, 0.01, 0.1]\n",
    "## Epochs \n",
    "EPOCHS=[30,40,50]\n",
    "## Sequence Length\n",
    "SEQ_LEN= [12,24,36,48,60,72]\n",
    "## Batch\n",
    "BATCH_VALUES=[16,32]\n",
    "## Loss Function Hyperparameter\n",
    "LOSS_PARAMS_LIST=[0.5,2,4,8,16]\n",
    "## AE Architecture hyperparameter\n",
    "RP = [0.5,0.6,0.7,0.8,0.9]\n",
    "NUM_TRIALS=100\n",
    "\n",
    "# Hyperparameters used in Transformer model\n",
    "## Dropout \n",
    "DROPOUT=[0.5,0.6,0.7]\n",
    "## d_ff\n",
    "d_ff_vals = [32,64]\n",
    "## N encoder\n",
    "N_vals = [1,2,3,4]\n",
    "## h heads\n",
    "h_vals =[2,4]\n",
    "## d_model\n",
    "d_model_vals = [16,64,128] # d_model%h ==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00df141-a2e4-41fd-b371-8340eb88fd97",
   "metadata": {},
   "source": [
    "## **Transformer Encoder Finetuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674340a6-7a57-46d6-ab0f-138dfdb05fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-06 09:11:52,814]\u001b[0m Trial 16 finished with value: 0.04793903443820869 and parameters: {'learning_rate': 0.0001, 'reduction_param': 0.5, 'epochs': 40, 'sequence_length': 36, 'batch_size': 16, 'loss_parameter': 0.5, 'h': 4, 'N': 2, 'd_ff': 32, 'd_model': 16, 'dropout': 0.7}. Best is trial 14 with value: 0.019942128411906807.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_length 36 batch_size 16 epochs 40\n",
      "total training batch number: 316\n",
      "total validation batch number: 79\n",
      "total test batch number: 2723\n",
      "Epoch 0: train loss: 0.1405529182262813, val loss: 0.12439560635557657\n",
      "Epoch 1: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 2: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 3: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 4: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 5: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 6: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 7: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 8: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 9: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 10: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 11: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 12: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 13: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 14: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 15: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 16: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 17: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 18: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 19: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 20: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 21: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 22: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 23: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 24: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 25: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 26: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n",
      "Epoch 27: train loss: 0.1375960275012104, val loss: 0.12439560635557657\n"
     ]
    }
   ],
   "source": [
    "config_ts_main = configue.load(\"./training/config_TS.yaml\")\n",
    "\n",
    "def objective_ts(trial: optuna.Trial): \n",
    "\n",
    "    config_ts = {\n",
    "        \"learning_rate\": trial.suggest_categorical('learning_rate', LR),\n",
    "        \"reduction_parameter\": trial.suggest_categorical('reduction_param', RP),\n",
    "        \"epochs\": int(trial.suggest_categorical('epochs', EPOCHS)),\n",
    "        \"sequence_length\": int(trial.suggest_categorical('sequence_length', SEQ_LEN)),\n",
    "        \"batch_size\": int(trial.suggest_categorical('batch_size', BATCH_VALUES)),\n",
    "        \"loss_parameter\": trial.suggest_categorical('loss_parameter', LOSS_PARAMS_LIST),\n",
    "        \"h\": trial.suggest_categorical('h', h_vals),\n",
    "        \"N\": trial.suggest_categorical('N', N_vals),\n",
    "        \"d_ff\": trial.suggest_categorical('d_ff', d_ff_vals),\n",
    "        \"d_model\": trial.suggest_categorical('d_model', d_model_vals),\n",
    "        \"dropout\": trial.suggest_categorical('dropout', DROPOUT),\n",
    "        \"models_path\": config_ts_main[\"models_path\"]\n",
    "    }\n",
    "\n",
    "    d_input = train.shape[1]\n",
    "    print('sequence_length',config_ts[\"sequence_length\"],'batch_size',config_ts[\"batch_size\"],'epochs',config_ts[\"epochs\"])\n",
    "    TS_model = make_model(d_input=d_input, N=config_ts[\"N\"], d_model=config_ts[\"d_model\"], d_ff=config_ts[\"d_ff\"], h=config_ts[\"h\"], dropout=config_ts[\"dropout\"])\n",
    "    if torch.cuda.is_available():\n",
    "        TS_model = TS_model.cuda()  \n",
    "        \n",
    "    train_loader_ts, val_loader_ts, test_loader_ts = generate_loaders_and_test_nan(config, config_ts,train, val, test, test_nan, test_mask)\n",
    "\n",
    "    loss_fn = ORT_MIT_Loss(config_ts[\"loss_parameter\"])\n",
    "    \n",
    "    train_loss_list, val_loss_list,TS_model_Path = train_model(TS_model,loss_fn,config_ts,d_input,train_loader_ts,val_loader_ts, is_flatten=False, is_TS=True, is_warmed= False)\n",
    "         \n",
    "    return val_loss_list[-1]\n",
    "\n",
    "study = optuna.create_study(study_name='deepl_finetune', direction='minimize') \n",
    "study.optimize(func=objective_ts, n_trials=NUM_TRIALS)  \n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: {:.5f}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ca3427-eee6-40c0-bc8e-d1680f7e7e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_parallel_coordinate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_parallel_coordinate\u001b[49m(study)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_parallel_coordinate' is not defined"
     ]
    }
   ],
   "source": [
    "plot_optimization_history(study)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f1d39-934c-4d6d-a5f2-ae47b4110a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a274355-dbf3-4010-8c09-1becb2fe34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
